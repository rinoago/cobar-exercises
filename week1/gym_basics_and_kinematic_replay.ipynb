{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with NeuroMechFly\n",
    "\n",
    "**Summary:** In this tutorial, we will introduce the basic concepts of interacting with the simulated fly in a Markov Decision Process using the Gym interface. As a demonstration, we will replay experimentally recorded leg kinematics during walking in the simulator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Decision Process (MDP) and the Gym API\n",
    "---------------------------------------------\n",
    "\n",
    "We formulated the control of NeuroMechFly as a partially observable Markov Decision Process (MDP). At each time step, the simulation provides the controller with an observation and, optionally, a user-defined reward. Then, the simulation receives an action from the controller and steps the physics forward accordingly. The observation space is a user-configurable subset of the state space including visual inputs, olfactory inputs, ground contacts, joint states (angles, angular velocities, and torques), and the position and velocity of the fly model within the arena. The action space includes the control signal (eg. angles for position control) for every actuated joint (eg. 7 degrees-of-freedom (DoFs) per leg * 6 legs) and the on/off signal for leg adhesion. This framework is easily extendable: the user can incorporate additional layers of sensory preprocessing or premotor computation into the MDP.\n",
    "\n",
    "| ![](https://github.com/NeLy-EPFL/_media/blob/main/flygym/mdp.png?raw=true) | \n",
    "|:--:| \n",
    "| *The biomechanical model and its interaction with the environment are encapsulated as a MDP task. A user-defined controller interfaces with the task through actions (red) and observations (blue). The user can extend the MDP task by adding preprogrammed processing routines for motor outputs (purple) and sensory inputs (light blue), to modify the action and observation spaces handled by the controller.* |\n",
    "\n",
    "\n",
    "Our implementation of the partially observable MDP complies with the [Gymnasium API](https://gymnasium.farama.org/). Gymnasium (a continuation of the now deprecated OpenAI Gym) is a package and standardized interface for developing and comparing control algorithms and benchmarking tasks. It provides a diverse collection of environments, ranging from classic control problems, Atari games, board games, and robotics simulations. Gym environments are designed to offer a common interface for controllers, in particular reinforcement learning agents, to interact with. This standardization makes it easier to develop and compare algorithms.\n",
    "\n",
    "The overall steps for interacting with a Gym environment are:\n",
    "\n",
    "1. Defining an environment\n",
    "2. Reset the environment and get the initial observation\n",
    "3. Interact with the environment with a loop:\n",
    "   - Based on the last observation, the controller decides which actions to take\n",
    "   - Step the simulation, applying the selected actions. The simulation will return you the new observation (and optionally some additional information)\n",
    "   - Optional: render the simulation graphically\n",
    "   - Break if certain conditions are met (eg. task is accomplished or failed), otherwise continue\n",
    "\n",
    "4. Close the environment and analyze the results\n",
    "\n",
    "This process is illustrated in the following code snippet:\n",
    "\n",
    "```Python\n",
    "env = MyEnvironment(...)\n",
    "obs, info = env.reset()\n",
    "\n",
    "for step in range(1000):    # let's simulate 1000 steps max\n",
    "    action = ...    # your controller decides what to do based on obs\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "```\n",
    "\n",
    "Note that the action can be selected by any means defined by the user (eg. preprogrammed rules, algorithmic models, artificial neural networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The action and observation spaces\n",
    "The **action** is a dictionary with the following keys and values:\n",
    "\n",
    "- **\"joints\"**: The control signal for the actuated DoFs (eg. if ``NeuroMechFly.control == \"position\"``, then this is the target joint angle). This is a NumPy array of shape (|actuated_joints|,). The order of the DoFs is the same as ``NeuroMechFly.actuated_joints``.\n",
    "- **\"adhesion\"** (if ``sim_params.enable_adhesion`` is True): The on/off signal of leg adhesion as a NumPy array of shape (6,), one for each leg. The order of the legs is: LF, LM, LH, RF, RM, RH (L/R = left/right, F/M/H = front/middle/hind).\n",
    "\n",
    "The **observation** is a dictionary with the following keys and values:\n",
    "\n",
    "- **\"joints\"**: The joint states as a NumPy array of shape (3, |actuated_joints|). The three rows are the angle, angular velocity, and force at each DoF. The order of the DoFs is the same as ``NeuroMechFly.actuated_joints``\n",
    "- **\"fly\"**: The fly state as a NumPy array of shape (4, 3). 0th row: x, y, z position of the fly in arena. 1st row: x, y, z velocity of the fly in arena. 2nd row: orientation of fly around x, y, z axes. 3rd row: rate of change of fly orientation.\n",
    "- **\"contact_forces\"**: Readings of the touch contact sensors, one placed for each of the body segments specified in ``NeuroMechFly.contact_sensor_placements``. This is a NumPy array of shape (|contact_sensor_placements|, 3)\n",
    "- **\"end_effectors\"**: The positions of the end effectors (most distal tarsus link) of the legs as a NumPy array of shape (6, 3). The order of the legs is: LF, LM, LH, RF, RM, RH (L/R = left/right, F/M/H = front/middle/hind). \n",
    "- **\"fly_orientation\"**: NumPy array of shape (3,). This is the vector (x, y, z) pointing toward the direction that the fly is facing.\n",
    "- **\"vision\"** (if ``sim_params.enable_vision`` is True): The light intensities sensed by the ommatidia on the compound eyes. This is a NumPy array of shape (2, num_ommatidia_per_eye, 2), where the zeroth dimension is the side (left, right in that order); the second dimension specifies the ommatidium, and the last column is for the spectral channel (yellow-type, pale-type in that order). Each ommatidium only has one channel with nonzero reading. The intensities are given on a [0, 1] scale.\n",
    "- **\"odor_intensity\"** (if ``sim_params.enable_olfaction`` is True): The odor intensities sensed by the odor sensors (by default 2 antennae and 2 maxillary palps). This is a NumPy array of shape (odor_space_dimension, num_sensors).\n",
    "\n",
    "### `terminated`, `truncated`, and the `info` dictionary\n",
    "In the Gym API, the `step()` method returns a `terminated` flag indicating whether the simulation has ended due to a condition under the MDP formulation (eg. task success/failure). The `step()` method also returns a `truncated` flag indicating whether the simulation has ended due to a condition outside the MDP formulation (eg. timeout). The provided `NeuroMechFly` environment always returns False for both `terminated` and `truncated`. The user can modify this behavior by extending the `NeuroMechFly` class.\n",
    "\n",
    "Additionally, the `step()` method returns an `info` dictionary that contains arbitrary auxilliary information. The user can add any information to this dictionary by extending the `NeuroMechFly` class. The provided `NeuroMechFly` contains the following keys and values in the **`info` dictionary**:\n",
    "\n",
    "- **\"raw_vision\"** (if ``sim_params.enable_vision`` and ``sim_params.render_raw_vision`` are both True): The eye camera rendering before it is transformed into ommatidia readings. This is a NumPy array of shape (2, nrows, ncols, 3) where the zeroth dimension is for the side (left, right in that order). The rest are the RGB image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Kinematic replay of experimentally recorded behavior\n",
    "\n",
    "We now move on to an example where we kinematically replay some experimentally recorded walking behaviors. Specifically, we recorded a tethered fly walking on an air-suspended spherical treadmill using seven zoomed-in cameras from different angles. We then estimated the 3D positions of keypoints on the joints using DeepFly3D (Günel et al., *Elife* 2019) and used inverse kinematics to calculate the angle at each DoF. With these we will use a PD controller to actuate the DoFs of the simulated fly at using these exact angles to see if the fly can walk untethered on flat terrain, as shown in the original NeuroMechFly paper (Lobato-Rios et al., *Nature Methods* 2022).\n",
    "\n",
    "We start with the necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "\n",
    "import flygym.common\n",
    "import flygym.mujoco\n",
    "import flygym.mujoco.preprogrammed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"outputs/\").mkdir(exist_ok=True)  # Create directory for generated videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some simulation parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = 1\n",
    "sim_params = flygym.mujoco.Parameters(\n",
    "    timestep=1e-4, render_mode=\"saved\", render_playspeed=0.2, draw_contacts=True\n",
    ")\n",
    "actuated_joints = flygym.mujoco.preprogrammed.all_leg_dofs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load recorded kinematics that are included with the FlyGym package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = flygym.common.get_data_path(\"flygym\", \"data\")\n",
    "with open(data_path / \"behavior\" / \"210902_pr_fly1.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is provided at 2000 Hz. We will try to run the simulation at $\\Delta t=0.0001s$ (10000 Hz), so let's interpolate it 5x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_num_steps = int(run_time / sim_params.timestep)\n",
    "data_block = np.zeros((len(actuated_joints), target_num_steps))\n",
    "input_t = np.arange(len(data[\"joint_LFCoxa\"])) * data[\"meta\"][\"timestep\"]\n",
    "output_t = np.arange(target_num_steps) * sim_params.timestep\n",
    "for i, dof in enumerate(actuated_joints):\n",
    "    data_block[i, :] = np.interp(output_t, input_t, data[dof])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the time series of DoF angles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    3, 2, figsize=(8, 6), sharex=True, sharey=True, tight_layout=True\n",
    ")\n",
    "legs = [\n",
    "    f\"{side} {pos} leg\"\n",
    "    for pos in [\"front\", \"middle\", \"hind\"]\n",
    "    for side in [\"Left\", \"Right\"]\n",
    "]\n",
    "for i, leg in enumerate(legs):\n",
    "    ax = axs.flatten()[i]\n",
    "    leg_code = f\"{leg.split()[0][0]}{leg.split()[1][0]}\".upper()\n",
    "    for j, dof in enumerate(actuated_joints):\n",
    "        if dof.split(\"_\")[1][:2] != leg_code:\n",
    "            continue\n",
    "        ax.plot(output_t, np.rad2deg(data_block[j, :]), label=dof[8:])\n",
    "    ax.set_ylim(-180, 180)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Angle (degree)\")\n",
    "    ax.set_yticks([-180, -90, 0, 90, 180])\n",
    "    ax.set_title(leg)\n",
    "    if leg == \"Right front leg\":\n",
    "        ax.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a NeuroMechFly simulation instance and play out the recorded kinematics in the MDP loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = flygym.mujoco.NeuroMechFly(\n",
    "    sim_params=sim_params,\n",
    "    init_pose=\"stretch\",\n",
    "    actuated_joints=actuated_joints,\n",
    "    control=\"position\",\n",
    ")\n",
    "obs, info = nmf.reset()\n",
    "for i in trange(target_num_steps):\n",
    "    # here, we simply use the recorded joint angles as the target joint angles\n",
    "    joint_pos = data_block[:, i]\n",
    "    action = {\"joints\": joint_pos}\n",
    "    obs, reward, terminated, truncated, info = nmf.step(action)\n",
    "    nmf.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the rendered video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.save_video(\"./outputs/kinematic_replay.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"./outputs/kinematic_replay.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the observation at the last step to see if they are consistent with our expectations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in obs.items():\n",
    "    print(f\"{k}: shape {v.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic NeuroMechFly simulation always returns 0 as the reward. It always returns False for the `terminated` and `truncated` flags. The `info` is also empty. The user can extend the `NeuroMechFly` class to modify these behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"reward: {reward}\")\n",
    "print(f\"terminated: {terminated}\")\n",
    "print(f\"truncated: {truncated}\")\n",
    "print(f\"info: {info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: effects of simulation parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will modify some simulation parameters to see their effects on *Drosophila* locomotion. For the description of simulation parameters, refer to https://neuromechfly.org/api_ref/parameters.html#flygym.mujoco.Parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the cell below to run the simulation with different values of `actuator_kp` (e.g., 10, 30 (default), 50). How does `actuator_kp` affect the walking behavior?\n",
    "\n",
    "TODO:\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_params_ = flygym.mujoco.Parameters(\n",
    "    timestep=1e-4,\n",
    "    render_mode=\"saved\",\n",
    "    render_playspeed=0.2,\n",
    "    draw_contacts=True,\n",
    "    # =========================================================================\n",
    "    # TODO: # modify actuator_kp\n",
    "    actuator_kp=30,\n",
    "    # =========================================================================\n",
    ")\n",
    "\n",
    "nmf = flygym.mujoco.NeuroMechFly(\n",
    "    sim_params=sim_params_,\n",
    "    init_pose=\"stretch\",\n",
    "    actuated_joints=actuated_joints,\n",
    "    control=\"position\",\n",
    ")\n",
    "obs, info = nmf.reset()\n",
    "for i in trange(target_num_steps):\n",
    "    joint_pos = data_block[:, i]\n",
    "    action = {\"joints\": joint_pos}\n",
    "    obs, reward, terminated, truncated, info = nmf.step(action)\n",
    "    nmf.render()\n",
    "\n",
    "nmf.save_video(\"./outputs/kinematic_replay_actuator_kp.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"./outputs/kinematic_replay_actuator_kp.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the simulation parameters to simulate the fly walking on a slippery surface.\n",
    "\n",
    "Hint 1: Refer to the documentation of the `friction` parameter in [flygym.mujoco.Parameters](https://neuromechfly.org/api_ref/parameters.html#flygym.mujoco.Parameters) and [flygym.mujoco.arena.FlatTerrain](https://neuromechfly.org/api_ref/arena.html#flygym.mujoco.arena.FlatTerrain).\n",
    "\n",
    "Hint 2: Setting the sliding friction coefficient to zero may lead to numerical errors. Use a small positive value (e.g., 2e-3) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flygym.mujoco.arena import FlatTerrain\n",
    "\n",
    "sim_params = flygym.mujoco.Parameters(\n",
    "    timestep=1e-4,\n",
    "    render_mode=\"saved\",\n",
    "    render_playspeed=0.2,\n",
    "    draw_contacts=True,\n",
    "    # =========================================================================\n",
    "    # TODO: add keyword argument to make the legs slippery\n",
    "\n",
    "    # =========================================================================\n",
    ")\n",
    "\n",
    "slippery_arena = FlatTerrain(\n",
    "    # =========================================================================\n",
    "    # TODO: add keyword argument to make the floor slippery\n",
    "\n",
    "    # =========================================================================\n",
    ")\n",
    "\n",
    "nmf = flygym.mujoco.NeuroMechFly(\n",
    "    sim_params=sim_params,\n",
    "    init_pose=\"stretch\",\n",
    "    actuated_joints=actuated_joints,\n",
    "    control=\"position\",\n",
    "    arena=slippery_arena,\n",
    ")\n",
    "\n",
    "obs, info = nmf.reset()\n",
    "for i in trange(target_num_steps):\n",
    "    joint_pos = data_block[:, i]\n",
    "    action = {\"joints\": joint_pos}\n",
    "    obs, reward, terminated, truncated, info = nmf.step(action)\n",
    "    nmf.render()\n",
    "\n",
    "nmf.save_video(\"./outputs/kinematic_replay_slippery.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"./outputs/kinematic_replay_slippery.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the simulation parameters to simulate the fly walking on floor with a 10° slope angle. The fly should struggle to walk forward initially and then fall backwards.\n",
    "Visualize the fall by plotting the z-position of the fly over time.\n",
    "\n",
    "\n",
    "Hint: Change the direction of the gravity. The fly should struggle to walk forward initially and then fall backwards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TODO: modify gravity\n",
    "# should look something like\n",
    "# gx = ...\n",
    "# gz = ...\n",
    "# gravity = (gx, 0, gz)\n",
    "\n",
    "gravity = ...\n",
    "# =============================================================================\n",
    "\n",
    "sim_params_ = flygym.mujoco.Parameters(\n",
    "    timestep=1e-4,\n",
    "    render_mode=\"saved\",\n",
    "    render_playspeed=0.2,\n",
    "    draw_contacts=True,\n",
    "    gravity=gravity,\n",
    "    align_camera_with_gravity=True,\n",
    ")\n",
    "\n",
    "nmf = flygym.mujoco.NeuroMechFly(\n",
    "    sim_params=sim_params_,\n",
    "    init_pose=\"stretch\",\n",
    "    actuated_joints=actuated_joints,\n",
    "    control=\"position\",\n",
    ")\n",
    "obs, info = nmf.reset()\n",
    "\n",
    "z_positions = []\n",
    "\n",
    "for i in trange(target_num_steps):\n",
    "    joint_pos = data_block[:, i]\n",
    "    action = {\"joints\": joint_pos}\n",
    "    obs, reward, terminated, truncated, info = nmf.step(action)\n",
    "    # =========================================================================\n",
    "    # TODO: get the z-position of the fly and append it to z_positions\n",
    "    z_position = ...\n",
    "    z_positions.append(z_position)\n",
    "    # =========================================================================\n",
    "    nmf.render()\n",
    "\n",
    "nmf.save_video(\"./outputs/kinematic_replay_10deg.mp4\")\n",
    "\n",
    "# plot the z position of the fly over time\n",
    "fig, ax = plt.subplots(figsize=(4, 2))\n",
    "ax.plot(output_t, z_positions, color=\"k\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"z (mm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"./outputs/kinematic_replay_10deg.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: extract kinematics for one step cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try to extract one complete the kinematics of one complete walking cycle, which can be repeated for an unlimited number of times to allow the fly to walk further. To accomplish this, we will locate the time interval for each walking cycle by detecting peaks in one of the joint angles, resample the kinematics of the walking cycles so that they are of the same length, and then average them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "# get the joint angle of the right hind leg tibia\n",
    "rh_tibia_angle = data_block[actuated_joints.index(\"joint_RHTibia\")]\n",
    "\n",
    "# ===============================================================================================\n",
    "# TODO: detect peaks in the tibia angle of the right hind leg using scipy.signal.find_peaks\n",
    "# see https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html for usage\n",
    "peak_frame_indices = ...\n",
    "# ===============================================================================================\n",
    "\n",
    "cycle_n_frames = round(np.diff(peak_frame_indices).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the tibia angle of the right hind leg with detected peaks\n",
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "ax.plot(output_t, rh_tibia_angle, color=\"C5\")\n",
    "\n",
    "for t in peak_frame_indices * sim_params.timestep:\n",
    "    ax.axvline(t, color=\"k\", ls=\"--\", alpha=0.3)\n",
    "\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Angle (degree)\")\n",
    "ax.set_title(\"Right hind tibia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "data_block_cycle = np.zeros((len(actuated_joints), cycle_n_frames))\n",
    "\n",
    "for a, b in np.lib.stride_tricks.sliding_window_view(peak_frame_indices, 2):\n",
    "    old_indices = np.arange(b - a)\n",
    "    new_indices = np.linspace(0, old_indices.max(), cycle_n_frames)\n",
    "    data_block_cycle += interp1d(old_indices, data_block[:, a:b])(new_indices)\n",
    "\n",
    "data_block_cycle /= len(peak_frame_indices) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot locomotor kinematics for two cycles\n",
    "fig, axs = plt.subplots(\n",
    "    3, 2, figsize=(5, 6), sharex=True, sharey=True, tight_layout=True\n",
    ")\n",
    "legs = [\n",
    "    f\"{side} {pos} leg\"\n",
    "    for pos in [\"front\", \"middle\", \"hind\"]\n",
    "    for side in [\"Left\", \"Right\"]\n",
    "]\n",
    "for i, leg in enumerate(legs):\n",
    "    ax = axs.flatten()[i]\n",
    "    leg_code = f\"{leg.split()[0][0]}{leg.split()[1][0]}\".upper()\n",
    "    for j, dof in enumerate(actuated_joints):\n",
    "        if dof.split(\"_\")[1][:2] != leg_code:\n",
    "            continue\n",
    "        angles = np.tile(np.rad2deg(data_block_cycle[j, :]), 2)\n",
    "        ax.plot(np.arange(len(angles)) * sim_params.timestep, angles, label=dof[8:])\n",
    "    ax.set_ylim(-180, 180)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Angle (degree)\")\n",
    "    ax.set_yticks([-180, -90, 0, 90, 180])\n",
    "    ax.set_title(leg)\n",
    "    ax.axvline(cycle_n_frames * sim_params.timestep, color=\"k\", ls=\"--\", alpha=0.3)\n",
    "    if leg == \"Right front leg\":\n",
    "        ax.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay the locomotor kinematics for two cycles\n",
    "sim_params_slow = flygym.mujoco.Parameters(\n",
    "    timestep=1e-4,\n",
    "    render_mode=\"saved\",\n",
    "    render_playspeed=0.02,\n",
    "    draw_contacts=False,\n",
    "    render_camera=\"Animat/camera_left\",\n",
    ")\n",
    "\n",
    "nmf = flygym.mujoco.NeuroMechFly(\n",
    "    sim_params=sim_params_slow,\n",
    "    init_pose=\"stretch\",\n",
    "    actuated_joints=actuated_joints,\n",
    "    control=\"position\",\n",
    ")\n",
    "obs, info = nmf.reset()\n",
    "for i in trange(cycle_n_frames * 2):\n",
    "    # here, we simply use the recorded joint angles as the target joint angles\n",
    "    joint_pos = data_block_cycle[:, i % cycle_n_frames]\n",
    "    action = {\"joints\": joint_pos}\n",
    "    obs, reward, terminated, truncated, info = nmf.step(action)\n",
    "    nmf.render()\n",
    "\n",
    "nmf.save_video(\"./outputs/kinematic_replay_2_cycles.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: alter locomotor kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "With the same simulation parameters and number of simulation steps, can you make the fly walk approximately twice as fast? (In *Drosophila*, changes in stance duration largely regulate walking speed, while stance amplitude and swing duration remain relatively constant (DeAngelis et al., 2019; Wosnitza et al., 2012). For simplicity, we will decrease both stance and swing durations here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = flygym.mujoco.NeuroMechFly(\n",
    "    sim_params=sim_params,\n",
    "    init_pose=\"stretch\",\n",
    "    actuated_joints=actuated_joints,\n",
    "    control=\"position\",\n",
    ")\n",
    "obs, info = nmf.reset()\n",
    "for i in trange(target_num_steps):\n",
    "    # =========================================================================\n",
    "    # TODO: replay the locomotor kinematics at 2× speed by skipping frames\n",
    "    # you will find the data_block_cycle and cycle_n_frames variables useful\n",
    "    joint_pos = ...\n",
    "    # =========================================================================\n",
    "    action = {\"joints\": joint_pos}\n",
    "    obs, reward, terminated, truncated, info = nmf.step(action)\n",
    "    nmf.render()\n",
    "\n",
    "nmf.save_video(\"./outputs/kinematic_replay_fast.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Can you make the fly backwards? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block_backwards = data_block_cycle.copy()\n",
    "\n",
    "# =============================================================================\n",
    "# TODO: modify the data_block_backwards to make the fly walk backwards\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot locomotor kinematics for two cycles\n",
    "fig, axs = plt.subplots(\n",
    "    3, 2, figsize=(5, 6), sharex=True, sharey=True, tight_layout=True\n",
    ")\n",
    "legs = [\n",
    "    f\"{side} {pos} leg\"\n",
    "    for pos in [\"front\", \"middle\", \"hind\"]\n",
    "    for side in [\"Left\", \"Right\"]\n",
    "]\n",
    "for i, leg in enumerate(legs):\n",
    "    ax = axs.flatten()[i]\n",
    "    leg_code = f\"{leg.split()[0][0]}{leg.split()[1][0]}\".upper()\n",
    "    for j, dof in enumerate(actuated_joints):\n",
    "        if dof.split(\"_\")[1][:2] != leg_code:\n",
    "            continue\n",
    "        angles = np.tile(np.rad2deg(data_block_backwards[j, :]), 2)\n",
    "        ax.plot(np.arange(len(angles)) * sim_params.timestep, angles, label=dof[8:])\n",
    "    ax.set_ylim(-180, 180)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Angle (degree)\")\n",
    "    ax.set_yticks([-180, -90, 0, 90, 180])\n",
    "    ax.set_title(leg)\n",
    "    ax.axvline(cycle_n_frames * sim_params.timestep, color=\"k\", ls=\"--\", alpha=0.3)\n",
    "    if leg == \"Right front leg\":\n",
    "        ax.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = flygym.mujoco.NeuroMechFly(\n",
    "    sim_params=sim_params,\n",
    "    init_pose=\"stretch\",\n",
    "    actuated_joints=actuated_joints,\n",
    "    control=\"position\",\n",
    ")\n",
    "obs, info = nmf.reset()\n",
    "for i in trange(target_num_steps):\n",
    "    joint_pos = data_block_backwards[:, i % cycle_n_frames]\n",
    "    action = {\"joints\": joint_pos}\n",
    "    obs, reward, terminated, truncated, info = nmf.step(action)\n",
    "    nmf.render()\n",
    "\n",
    "nmf.save_video(\"./outputs/kinematic_replay_backwards.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flygym0.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
