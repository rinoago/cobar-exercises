{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encapsulating custom code into Gym environments: A turning controller\n",
    "\n",
    "**Summary:** In this tutorial, we will demonstrate how one can build controllers at different levels of abstraction by implementing Gym environments encoding variable amounts of preprogrammed computation. As an example, we will implement turning by asymmetrically modulating the amplitude and frequency of CPGs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gym environments and MDP\n",
    "\n",
    "So far, we have interacted with the `NeuroMechFly` class which implements the [Gym interface](https://gymnasium.farama.org/): it has an action space (input given by the user), an observation space (output returned to the user), a `.step(...)` method, a `.reset(...)` method, and a `.render(...)` method. The action and observation spaces of `NeuroMechFly` are as follows:\n",
    "\n",
    "- Action space:\n",
    "    - \"joints\": 42-dimensional real vector ∈ [0, 2π] indicating joint angles (in default position control mode)\n",
    "    - \"adhesion\": 6-dimensional integer vector ∈ {0, 1} indicating whether adhesion is turned on for each leg\n",
    "- Observation space:\n",
    "    - \"joints\": shape (3, 42) real array indicating joint angles (0th row), velocities (1st row), and torques (2nd row)\n",
    "    - \"fly\": shape (4, 3) real array indicating fly xyz positions (0th row), xyz velocities (1st row), yaw-pitch-roll angles (2nd row), and yaw-pitch-roll velocities (3rd row)\n",
    "    - \"contact_forces\": shape (N, 3) - contact forces, in xyz directions, of the N segments defined in `contact_sensor_placements`\n",
    "    - \"end_effectors\": shape (6, 3) - xyz positions of the six legs in the order of LF, LM LH, RF, RM, RH\n",
    "    - \"fly_orientation\": shape (3,) - unit vector indicating the fly's heading orientation\n",
    "\n",
    "\n",
    "The FlyGym package is designed to be expandable: the user can implement their own Gym environments with different action and observation spaces and implement different logics (e.g. preprogrammed premotor computation and sensory processing). This is illustrated in the figure below:\n",
    "\n",
    "<img src=\"https://github.com/NeLy-EPFL/_media/blob/main/flygym/mdp.png?raw=true\" alt=\"rule_based\" width=\"500\"/>\n",
    "\n",
    "In the CPG controller that [we have implemented](https://github.com/NeLy-EPFL/cobar-exercises-internal/blob/main/week2/1_cpg_controller.ipynb), the underlying CPG network and the correction mechanisms can be considered the user-defined premotor computation (purple). The whole controller can be considered the box indicating the Markov Decision Process (MDP). Here, we will add a 2D descending signal that encodes turning. The action and observation spaces of our MDP \"box\" are as follows:\n",
    "\n",
    "- Action space: a 2-dimensional real vector describing the velocity on each side of the body. Although in principle the range of the amplitude is unrestricted, its absolute value shouldn't go far beyond 1 because otherwise the steps become very unrealistic.\n",
    "- Observation space: same as above (no sensory processing logic indicated in cyan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach for turning\n",
    "\n",
    "We will use a 2-dimensional representation of descending signals $[\\delta_L, \\delta_R] \\in \\mathbb{R}^2$ to modulate the amplitude and direction of the leg CPGs on each side of the body. Specifically, we will modulate the intrinsic amplitude $R'$ and intrinsic frequency $\\nu'$ on each side by:\n",
    "\n",
    "$$\n",
    "R'(\\delta) = |\\delta|\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nu_i'(\\delta) = \\begin{cases}\n",
    "\\nu_i   & \\text{if } \\delta>0\\\\\n",
    "-\\nu_i  & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "In other words, the magnitude of the descending signal controls the amplitude of stepping (as a gain applied to the originally recorded step size); the sign of the descending signal controls the direction of stepping. Of course, this is a very simplified model of turning. Perhaps the most unrealistic aspect of it is that it assumes that the step size spans linearly from 0 to 1x the recorded \"real\" step size. This is an area for future improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the `TurningController` class\n",
    "\n",
    "A key idea of the Gym interface is that it allows users to encapsulate the control logic in a Gym environment (a MDP), and expose only the input and output (action and observation) to the controller. This is achieved using [class inheritance](https://www.w3schools.com/python/python_inheritance.asp) in Python. Briefly, it allows a new class (subclass or child class) to inherit attributes and methods from an existing class (base class or parent class), enabling code reuse and the creation of hierarchical relationships between classes. Refer to the tutorial linked above to familiarize yourself with this concept.\n",
    "\n",
    "All Gym environments inherit from the `gymnasium.Env` class. You can refer to [the API reference of this class](https://gymnasium.farama.org/api/env/#gymnasium-env) for a full specification, or [this page](https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/) for a tutorial on how to make your own custom environment. The `NeuroMechFly` class we have used so far inherits from it and therefore complies with its specifications. Here, we will build a `TurningController` class that inherits from `NeuroMechFly` to provide a simplified interface to control turning via a 2D input space, which can be interpreted as a descending code.\n",
    "\n",
    "First, let's do the necessary imports and define the default parameter as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "from flygym.mujoco import Parameters, NeuroMechFly\n",
    "from flygym.mujoco.examples.common import PreprogrammedSteps\n",
    "from flygym.mujoco.examples.cpg_controller import CPGNetwork\n",
    "\n",
    "\n",
    "_tripod_phase_biases = np.pi * np.array(\n",
    "    [\n",
    "        [0, 1, 0, 1, 0, 1],\n",
    "        [1, 0, 1, 0, 1, 0],\n",
    "        [0, 1, 0, 1, 0, 1],\n",
    "        [1, 0, 1, 0, 1, 0],\n",
    "        [0, 1, 0, 1, 0, 1],\n",
    "        [1, 0, 1, 0, 1, 0],\n",
    "    ]\n",
    ")\n",
    "_tripod_coupling_weights = (_tripod_phase_biases > 0) * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define the `__init__` method of our `TurningNMF` class.\n",
    "\n",
    "We start with initializing the parent class by calling `super().__init__(...)`. This basically calls the `__init__` logic of the parent `NeuroMechFly` class using the specified parameters:\n",
    "\n",
    "```python\n",
    "class TurningNMF(NeuroMechFly):\n",
    "    def __init__(\n",
    "        self,\n",
    "        preprogrammed_steps=None,\n",
    "        intrinsic_freqs=np.ones(6) * 12,\n",
    "        intrinsic_amps=np.ones(6) * 1,\n",
    "        phase_biases=_tripod_phase_biases,\n",
    "        coupling_weights=_tripod_coupling_weights,\n",
    "        convergence_coefs=np.ones(6) * 20,\n",
    "        init_phases=None,\n",
    "        init_magnitudes=None,\n",
    "        amplitude_range=(-0.5, 1.5),\n",
    "        seed=0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # Initialize core NMF simulation\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the arguments as class attributes:\n",
    "\n",
    "```python\n",
    "        ...\n",
    "        \n",
    "        if preprogrammed_steps is None:\n",
    "            preprogrammed_steps = PreprogrammedSteps()\n",
    "        self.preprogrammed_steps = preprogrammed_steps\n",
    "        self.intrinsic_freqs = intrinsic_freqs\n",
    "        self.intrinsic_amps = intrinsic_amps\n",
    "        self.phase_biases = phase_biases\n",
    "        self.coupling_weights = coupling_weights\n",
    "        self.convergence_coefs = convergence_coefs\n",
    "        self.amplitude_range = amplitude_range\n",
    "\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to override the action space of `NeuroMechFly`. This is done by defining a new Gym space object. Gym provides an [interface for various space types](https://gymnasium.farama.org/api/spaces/). An non-exhaustive list includes `Box` for a possibly-bounded box in $\\mathbb{R}^n$, `Discrete` for a finite set of options, `Text` for text, and various [composite spaces](https://gymnasium.farama.org/api/spaces/composite/) such as `Dict`, `Tuple`, `Sequence`, `Graph`. Here, we will define the descending space as a `Box` space. We won't change the observation space definition since we will return `NeuroMechFly`'s observation as is:\n",
    "\n",
    "```python\n",
    "        ...\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.Box(*amplitude_range, shape=(2,))\n",
    "\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will initialize the CPG network that we defined [in the CPG tutorial](https://neuromechfly.org/tutorials/cpg_controller.html):\n",
    "\n",
    "```python\n",
    "        ...\n",
    "        \n",
    "        # Initialize CPG network\n",
    "        self.cpg_network = CPGNetwork(\n",
    "            timestep=self.sim_params.timestep,\n",
    "            intrinsic_freqs=intrinsic_freqs,\n",
    "            intrinsic_amps=intrinsic_amps,\n",
    "            coupling_weights=coupling_weights,\n",
    "            phase_biases=phase_biases,\n",
    "            convergence_coefs=convergence_coefs,\n",
    "            seed=seed,\n",
    "        )\n",
    "        self.cpg_network.reset(init_phases, init_magnitudes)\n",
    "\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we shall define the `reset` method of our `TurningController` class. This involves resetting the underlying `NeuroMechFly` simulation — as before, we will call `super().reset(...)` to drop in the reset method of the parent class. Then, we will reset the CPG network. Note that the `**kwargs` argument is required to fully comply with the Gym API. In general, this gives the user more flexibility to pass additional arguments when initializing the Gym environment.\n",
    "\n",
    "```Python\n",
    "    def reset(self, seed=None, init_phases=None, init_magnitudes=None, **kwargs):\n",
    "        obs, info = super().reset(seed=seed)\n",
    "        self.cpg_network.random_state = np.random.RandomState(seed)\n",
    "        self.cpg_network.reset(init_phases, init_magnitudes)\n",
    "        return obs, info\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to implement the most important `step` method. We start by updating the intrinsic amplitudes and frequencies of the CPGs as formulated above:\n",
    "\n",
    "```Python\n",
    "    def step(self, action):\n",
    "        \"\"\"Step the simulation forward one timestep.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        action : np.ndarray\n",
    "            Array of shape (2,) containing descending signal encoding\n",
    "            turning.\n",
    "        \"\"\"\n",
    "        # update CPG parameters\n",
    "        amps = np.repeat(np.abs(action[:, np.newaxis]), 3, axis=1).ravel()\n",
    "        freqs = self.intrinsic_freqs.copy()\n",
    "        freqs[:3] *= 1 if action[0] > 0 else -1\n",
    "        freqs[3:] *= 1 if action[1] > 0 else -1\n",
    "        self.cpg_network.intrinsic_amps = amps\n",
    "        self.cpg_network.intrinsic_freqs = freqs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can step the CPG:\n",
    "\n",
    "```Python\n",
    "        ...\n",
    "        \n",
    "        self.cpg_network.step()\n",
    "\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we write a loop to go through each of the legs. In this loop, we calculate the target joint angles using the preprogrammed step class and decide whether adhesion should be turned off for swinging:\n",
    "\n",
    "```python\n",
    "        ...\n",
    "        \n",
    "        joints_angles = []\n",
    "        adhesion_onoff = []\n",
    "        for i, leg in enumerate(self.preprogrammed_steps.legs):\n",
    "            # get target angles from CPGs and apply correction\n",
    "            my_joints_angles = self.preprogrammed_steps.get_joint_angles(\n",
    "                leg,\n",
    "                self.cpg_network.curr_phases[i],\n",
    "                self.cpg_network.curr_magnitudes[i],\n",
    "            )\n",
    "            joints_angles.append(my_joints_angles)\n",
    "\n",
    "            # get adhesion on/off signal\n",
    "            my_adhesion_onoff = self.preprogrammed_steps.get_adhesion_onoff(\n",
    "                leg, self.cpg_network.curr_phases[i]\n",
    "            )\n",
    "            adhesion_onoff.append(my_adhesion_onoff)\n",
    "\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we build the action dictionary (recall from our discussion on Gym spaces above — this is a composite `Dict` space) and call the `step` method of the parent `NeuroMechFly` class using it. This concludes the definition of our `step` method.\n",
    "\n",
    "```Python\n",
    "        ...\n",
    "        \n",
    "        action = {\n",
    "            \"joints\": np.array(np.concatenate(joints_angles)),\n",
    "            \"adhesion\": np.array(adhesion_onoff).astype(int),\n",
    "        }\n",
    "        return super().step(action)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put the code together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurningNMF(NeuroMechFly):\n",
    "    def __init__(\n",
    "        self,\n",
    "        preprogrammed_steps=None,\n",
    "        intrinsic_freqs=np.ones(6) * 12,\n",
    "        intrinsic_amps=np.ones(6) * 1,\n",
    "        phase_biases=_tripod_phase_biases,\n",
    "        coupling_weights=_tripod_coupling_weights,\n",
    "        convergence_coefs=np.ones(6) * 20,\n",
    "        init_phases=None,\n",
    "        init_magnitudes=None,\n",
    "        amplitude_range=(-0.5, 1.5),\n",
    "        seed=0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # Initialize core NMF simulation\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if preprogrammed_steps is None:\n",
    "            preprogrammed_steps = PreprogrammedSteps()\n",
    "        self.preprogrammed_steps = preprogrammed_steps\n",
    "        self.intrinsic_freqs = intrinsic_freqs\n",
    "        self.intrinsic_amps = intrinsic_amps\n",
    "        self.phase_biases = phase_biases\n",
    "        self.coupling_weights = coupling_weights\n",
    "        self.convergence_coefs = convergence_coefs\n",
    "        self.amplitude_range = amplitude_range\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.Box(*amplitude_range, shape=(2,))\n",
    "\n",
    "        # Initialize CPG network\n",
    "        self.cpg_network = CPGNetwork(\n",
    "            timestep=self.sim_params.timestep,\n",
    "            intrinsic_freqs=intrinsic_freqs,\n",
    "            intrinsic_amps=intrinsic_amps,\n",
    "            coupling_weights=coupling_weights,\n",
    "            phase_biases=phase_biases,\n",
    "            convergence_coefs=convergence_coefs,\n",
    "            seed=seed,\n",
    "        )\n",
    "        self.cpg_network.reset(init_phases, init_magnitudes)\n",
    "\n",
    "    def reset(self, seed=None, init_phases=None, init_magnitudes=None, **kwargs):\n",
    "        obs, info = super().reset(seed=seed)\n",
    "        self.cpg_network.random_state = np.random.RandomState(seed)\n",
    "        self.cpg_network.intrinsic_amps = self.intrinsic_amps\n",
    "        self.cpg_network.intrinsic_freqs = self.intrinsic_freqs\n",
    "        self.cpg_network.reset(init_phases, init_magnitudes)\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Step the simulation forward one timestep.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action : np.ndarray\n",
    "            Array of shape (2,) containing descending signal encoding\n",
    "            turning.\n",
    "        \"\"\"\n",
    "        # update CPG parameters\n",
    "        amps = np.repeat(np.abs(action[:, np.newaxis]), 3, axis=1).flatten()\n",
    "        freqs = self.intrinsic_freqs.copy()\n",
    "        freqs[:3] *= 1 if action[0] > 0 else -1\n",
    "        freqs[3:] *= 1 if action[1] > 0 else -1\n",
    "        self.cpg_network.intrinsic_amps = amps\n",
    "        self.cpg_network.intrinsic_freqs = freqs\n",
    "\n",
    "        self.cpg_network.step()\n",
    "\n",
    "        joints_angles = []\n",
    "        adhesion_onoff = []\n",
    "        for i, leg in enumerate(self.preprogrammed_steps.legs):\n",
    "            # get target angles from CPGs and apply correction\n",
    "            my_joints_angles = self.preprogrammed_steps.get_joint_angles(\n",
    "                leg,\n",
    "                self.cpg_network.curr_phases[i],\n",
    "                self.cpg_network.curr_magnitudes[i],\n",
    "            )\n",
    "            joints_angles.append(my_joints_angles)\n",
    "\n",
    "            # get adhesion on/off signal\n",
    "            my_adhesion_onoff = self.preprogrammed_steps.get_adhesion_onoff(\n",
    "                leg, self.cpg_network.curr_phases[i]\n",
    "            )\n",
    "            adhesion_onoff.append(my_adhesion_onoff)\n",
    "\n",
    "        action = {\n",
    "            \"joints\": np.array(np.concatenate(joints_angles)),\n",
    "            \"adhesion\": np.array(adhesion_onoff).astype(int),\n",
    "        }\n",
    "        return super().step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = 1\n",
    "timestep = 1e-4\n",
    "contact_sensor_placements = [\n",
    "    f\"{leg}{segment}\"\n",
    "    for leg in [\"LF\", \"LM\", \"LH\", \"RF\", \"RM\", \"RH\"]\n",
    "    for segment in [\"Tibia\", \"Tarsus1\", \"Tarsus2\", \"Tarsus3\", \"Tarsus4\", \"Tarsus5\"]\n",
    "]\n",
    "\n",
    "sim_params = Parameters(\n",
    "    timestep=1e-4,\n",
    "    render_mode=\"saved\",\n",
    "    render_camera=\"Animat/camera_top\",\n",
    "    render_playspeed=0.1,\n",
    "    enable_adhesion=True,\n",
    "    draw_adhesion=True,\n",
    ")\n",
    "\n",
    "nmf = TurningNMF(\n",
    "    sim_params=sim_params,\n",
    "    contact_sensor_placements=contact_sensor_placements,\n",
    "    spawn_pos=(0, 0, 0.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Gymnasium's `env_checker` utility to check if our `TurningNMF` class fully complies with the Gym API. To do this, `env_checker` will reset our environment a few times with random parameters and step it with random actions. It will then check if the observations are as specified in the observation space definition. If no exception is raised, we are in good shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(nmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the simulation, applying a steady [1.2, 0.2] turn throughout. We will also record the magnitude of the CPGs over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_hist = []\n",
    "obs, info = nmf.reset(seed=0)\n",
    "for i in trange(int(run_time / nmf.sim_params.timestep)):\n",
    "    curr_time = i * nmf.sim_params.timestep\n",
    "    action = np.array([1.2, 0.2])\n",
    "    obs, reward, terminated, truncated, info = nmf.step(action)\n",
    "    nmf.render()\n",
    "    magnitude_hist.append(nmf.cpg_network.curr_magnitudes.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the time series of the CPG magnitudes. As expected, three CPGs converge to a faster step while the others converge to a smaller one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p outputs\n",
    "t = np.arange(0, run_time, nmf.sim_params.timestep)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3), tight_layout=True)\n",
    "for ts in np.array(magnitude_hist).T:\n",
    "    ax.plot(t, ts)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"CPG magnitude\")\n",
    "fig.savefig(\"./outputs/turning_cpg_magnitude.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a look at the video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "nmf.save_video(\"./outputs/turning.mp4\")\n",
    "Video(\"./outputs/turning.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "In this exercise, let's quantify how much the fly turns over time with a descending signal of [0.2, 1.2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = 6\n",
    "obs, info = nmf.reset(seed=0)\n",
    "obs_hist = []\n",
    "\n",
    "for i in trange(int(run_time / nmf.sim_params.timestep)):\n",
    "    action = np.array([0.2, 1.2])\n",
    "    obs = nmf.step(action)[0]\n",
    "    obs_hist.append(obs)\n",
    "    nmf.render()\n",
    "\n",
    "nmf.save_video(\"./outputs/turning_6s.mp4\")\n",
    "Video(\"./outputs/turning_6s.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the change in the heading angle over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# TODO: Calculate the change in heading angle over time (~3 lines of code)\n",
    "# Hint 1: Which element of the observation dictionary contains the heading angle?\n",
    "# Hint 2: Use numpy.unwrap to handle the 2pi wrap-around:\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.unwrap.html\n",
    "\n",
    "heading_angle_change = ...\n",
    "#################################################################################\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3), tight_layout=True)\n",
    "t = np.arange(0, run_time, nmf.sim_params.timestep)\n",
    "ax.plot(t, heading_angle_change, c=\"k\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Heading angle change (rad)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the amount of turning is linearly correlated to the elapsed time. Let's define a function to calculate the slope of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(x, y):\n",
    "    ################################################################################\n",
    "    # TODO: Calculate the slope of the line\n",
    "    # Hint: Instead of implementing linear regression yourself, you can\n",
    "    # existing implementations, such as the linear_regression function from\n",
    "    # the statistics module in the Python standard library:\n",
    "    # https://docs.python.org/3/library/statistics.html#statistics.linear_regression\n",
    "\n",
    "    slope = ...\n",
    "    ################################################################################\n",
    "\n",
    "    return slope\n",
    "\n",
    "\n",
    "turning_speed = get_slope(t, heading_angle_change)\n",
    "print(f\"Turning speed = {turning_speed} rad/s\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3), tight_layout=True)\n",
    "t = np.arange(0, run_time, nmf.sim_params.timestep)\n",
    "ax.plot(t, heading_angle_change, c=\"k\")\n",
    "ax.plot(t, turning_speed * t, ls=\"--\", c=\"r\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Heading angle change (rad)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2:\n",
    "In theory, we have the capability to modulate the fly's turning using a scalar signal rather than a 2D descending signal.\n",
    "\n",
    "Let's create a class whose action space is $[-1, 1]\\in\\mathbb{R}$. In this space, the signals -1, 0, and 1 correspond to turning left, walking forward, and turning right, respectively. We can achieve this by extending the functionality of the existing `TurningNMF` class and incorporating the conversion from a 1D to a 2D descending signal inside the `step` method. The conversion process is illustrated in the diagram below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPoAAADjCAIAAAAjV545AAAACXBIWXMAABcRAAAXEQHKJvM/AAAgAElEQVR4nO2dfVxT9/XHTygilERIOkedYDUUh51CbVCROh8oYetofz91JrV9if72FKQ6f66Cya+trWttl6htnZvVxLVTsZ0Sa+lWakcipdYCVlIQnaKUSHkoUtuEhyAPIvz++Oo1JuEhyU0u3HveL/4I33tz7+HFJyfne8653y+vv78fEIQbBDBtAIL4D5Q7wiFQ7giHGAVyt1qtvGGj0WiYtTYhIcFjM6xWa0ZGBvlDRCIR7bYho0Du3CEjI0On0zkMyuVyHo+nUqkYMYlljAK5C4XC/juxWCzkkFqtdjikVCqZtdZjrFarXq8HAK1Wa/83IjQyCuTONSQSCdMmsBaUO8IhWCV3jUbD4/ESEhKcD4lEIh6PR6IFANDr9SqVivyq0+ns55cmk0mlUpEYWqPRkDfyeLzo6Ghv5sEqlYq6lEgkso/F9Xq9/dyUGCOXy8kLYiT503g8nslk8tgGJJBpA5jBZDJpNBqlUmk2mx1mgUajUaPRyGQyvV5vNBqpcepMd6cHJpNJLpebzWZqxGq1ajQao9FoMBiEQqF3fwriBqzy7u5CHHlKSkpubq7DNNdoNBqNRqVSSU2OU1JSAECj0Vit1uHfwmq1Eq2npKSUlZWRq2m1WrFYbDKZpFIpAMhkMvu5KTktNzeXvJDJZABAWYKRvTdwWu5Go1GhUBgMBiIpe6xWq1qtVqvV5FehUJibmysUCq1Wq1vhhEajIVo3GAyUUhUKRVlZmVAoNJlMVHyF+AFOyx0GjkyEQqHDISrqcMu7EzU730UoFJLPmH28hPgajsbuBLFYLBaLBzrk/fXNZjMJ2UnQ4hKcevoTTnt3WjQ9CMP5HrCfwiK+htNy93VWhPo4UZNUZ7B66k84IXez2exWwE0XQqGQKB4jlhECq+ROvLWzsp37rvwGmY+6NIBUkbD3y5+wSu4k02c2m6mpIWmpZbArWKlUkoRjQkIClXMkyXiTySQUChUKxXCug98PtMA2uRP1GI1Gqlyv0+lSUlKYqs4IhUJSOiW1VcoqqvlxyOkysZz6i1D33sAquQOAVqtVq9XUHFQsFqvValJIUiqVjIheIpHU1NQQN08NKhSKmpoa5/KWMwqFghR0Ee/h4UoECHdgm3dHkEFAuSMcAuWOcAiUO8IhUO4Ih0C5IxwC5Y5wCJQ7wiFQ7giHQLkjHALljnAIVsn9hZJVWSeW+vmmZFEkCvv+9TzDV+teOj532TvkZ91LxwtL6jy4RddunWVyTNfuO5rmVSqV/X2xU3I4sOfR7IKvD3/X2XR3IJ9pQ26i0Z7KM3xlP3K68srpyitPr5iZvviB4V+nv7W16x+H6LaOo7BB7l9+e4L8MGiDRCIpKyujfs0zfEW0Pivu3lc2/FQQGtTYbNNoT52uvPLmwfJYsWhW3L3Duew1zbae/GN9dfXOh6hlcEQiESOPJo5GRrfcs04svdZrY9oKF3xgqAaAWLFo5wuPkJGJEfydLzyybM0Hjc22PEP14HLv2q27ptnmD0M5Bqti9xFCY7OtymwBgP+WxjgcIiOnK68wYBYywr17wdeH82reWhz9m9T7nnB5wvb5R6nXX3574m/ntvjLtMG4aL65loazC48ViwCgvaOnymwhr10SnKkIzrz9DGvb40t6z57zgaWcA727a+RyuccPdDc22wBAEBo0McJx3hwbfVPi3zSPxBiM9Yxo784gSqUyISFBLBYP53FSl4zjBzkPCkKDBKFB7R09bbYe7wxEPAG9u2skEolSqfTMx7fbugFAEOpC7rfP6UC5MwDKfUDUarVEIlGpVHK5nGlbEHpgv9xNJtPwt2V1gJQq9Xp9dHT08O8o4I+FWxG8A+0dPcSvD+77ER8xsmJ39ek1de3VDoN5NW/l1bxF/TpJEKOatWv415RIJB4vLpKQkGAymRQKhVar9ewKA+Eyskd8Dfu9u8dkZGSYTKbc3Fx3tU48d3tHj7ODr6qx2J+D+JmR5d0d3PaQeXffYTQadTpdbm6uB5kZKt1+uvLKROn99odI+UkQGjTMJgKEXtC7u0alUmm1Ws+ykBMj+KSERFoJ7LnZXBA9YIEJ8Skod9eUlZUNc21el5BmgSqzZd1Lx8nctL2jZ91Lx0l4s9iuuYDq48U9yfzAyApmWMNi6f2nK5sKS+pOV15JXXWHjtMXP5A8dxJThnEclLuveGXDT/MMXxWWfE01hM2Ku3exNAa1ziQD7RmEDJPc3Fy4le70GLJvq8fvhUG3f0IoMHZnHr1eb7VacTtsP4ByZxiyUb1MJvP1rpcIjEa5L1iw8Mj7R5i2whGqVcHdrcWMRqNEIiERkVtQKR18cm/4jLKp6o6dO+66K2DZkmVMG0IbA+1Sj/iC0bRZTUVFxcyZM8vLyx988EGmbUFGJaMmmGlpacnOztLpdKh1xGNGjdx3/HlHWFjY7373O6YNQUYxvo3d+9vaeOPGeX+doqKiPbv3lJaWen8phMv41rt3HznafeTo0OcNSktLy//+7/qXX3558uTJdBiFcBffTlVbHl4YEDlx3OF3vLlIVvaGtrY2nXYvXVYhnMWHwUxPgaGvsbGvsbGvoTEgcqJnF8nLy8s58M7Fi1X02oZwEx8GM11v7bv54u2/e3aFlpaWjIzVB9/NCQ8Pp80shMP4Kpjpa2hsmbfw5j0EgvDPizyYsyoyftd7vfdtTz8tCOKAr7x75xs7qdf97e1db+9z9wr6I/pTpadff/0NOs1CuI1PvLu9a795GzcdfG1t7Zw5iYcPH1q4cOGQJyPIMPGJd7d37QR3HXxW1obfr1+LWkfohX659zU0dr/nItfe9da+/ra24Vxh79691dU1azPX0m0awnXol7uzaycM08FXVFRs2rTpz3/egdkYhHZojt2vl55qX75iwJsJBGHH/jV4Dn7BgoVLfrl4/br1NFqFIASavfu1Pw62oUB/e/vgJ2zdujUoKBC1jvgIOquqXW/vu3FhiPJnj8F4vfTUmMQ5zocqKiqUSmV5eTmNJiGIPbQFM30Nja2PPt7f3j7kmQETJ4Yd+6dzUlIqTZFKUzdu3EiLPQjiDG3BjG3DRget3zUt9uY9Jt4RrPc1NnbucJzObv7j5rCwMNQ64lPoCWa63t7Xe+oL8jpg4sSgn6UE//pXAZETLZNjACD886Ib5y90H3mvW3+UfCS63t4fmDgnKFVK3oLt7Ih/oCGYuXH+Qusv/osnEASlSoNkS+3jciJ3Ue3tlUF7CgzX/23sfu8oTyAYd/idux6Y1tLSsmDBwrVr1+CTSoivoUHuHRuUY36WQrlqe5zlTuhva+spMPY1NISsX7flT1sqTOVHjrznpRkIMiS+fbxjILlT5OXlZWSsvnixCotKiB9g8tFsbGdH/AyTct+ozE5Le1T6iIsoCEF8AWOriBmOGz7I+xc+lYf4E2a8e21t7Yqn0g8fPoRhDOJPmJE7trMjjMBAMEPa2f/2t7eGPhVBaMXfcq+trd20adOhQxjGIAzg72AmK2vD6szVGMYgjOBXuW/durW1tXXzi5v9eVMEofBfMDN4O3uDrebM1eK0Kel+swfhIP7z7tnZWRqNxnl19s5eW/7lnFe/yIzkR/vNGISb+Mm779i5o6en17mdvbSp4MPLOZauZlFwRPz4JP8Yg3AWf8i9qKhI/araoZ2dEjr59TEMYxDf4w+5f1byGbU6e2evrbD+/ZKmAkroABASGIquHfED/pD7pv/bBABnrhaXNBVUflfsfEJy1NKQQL4fLEE4js/lXvtfwR9e2HbmanFnb8dA5yROSPW1GQgCvn6840ri1DOLxxUkRQ2idYIoOOKe4IipwvhIfnSkIPqe4AjfWYVwFn88zRTyVXlh/fuF9Uddin7sXSHdNzodBkXBEZH86KnCuPjxD6P0Ebrw38N7nb22Dy/nfFL/vsM5ouCILUk5l6xnLF3N9baahvaa6pZKhxPixydNDY/n+HRWpVJpNJrhnCkUCi0Wi6/t8QC9Xi+Xyz0zT6PRqFQqiURSVlbmsQH+q6qGBPJlMZlzJ6TqL+22F7Slq7nBVjNVGA8AibcGG2w1l6xnLlkrK78rtnQ1f1L//if175METvwPHua47pEhkcvler1eqVSq1Wr7cX+3iEXyo//w0PZlMatDAkOpwUvWM86nJUctXR23+c3kgowZmxdFLREFR3T2dpQ2GbRnN284sURfvft7u1QmF1Cr1f13olQqAUAoFDqMj0zXPhJg5uG95Kil8eMf1la+2GAzA8Ala2Vy1NKBTo4fnxQ/PkkWk9lgqylpKjhz9ba/jwmPmzshFRM7owWZTObT4HlIGHs0+57giGdn71kUtQQAXCbjnYnkR8tiMrck5WTM2Jw4QQoA1S2VBy5sf744vbD+aGevzbcWI6MfJlciAABZTObKaVkAcObqsBRPiB+ftHJa9mvzj6ZNSRcFR1i6mo9U73m+OD3/cg6KHgBEIhGPx9Pr9Q7jGo2Gx+MlJCRQIyqVSqVSAYDVas3IyODxeCKRCABMJpNKpdLpdORd5II8Hi86Ono402W9Xq9SqYgBOp0uISGBx+NpNBq9Xk/dwh6z2axSqXi3kEqler2eDDrfzmq12p/sYBK5F7k1+Xt5PJ7JZLp5uN+XfH/f/d/fd/+Qp120VHxoPuDxXUq++fdzn6/IPC7NPC595tPFH5oPXLve7vHVRhEDxe5CoRAAcnNzHcbJvE0ikZBfqRC/pqZGLBaT1+Rq5EyZTJaSkuKsZudZhEvDHGaKarU6NzfX2eDc3FxisAMymczeWnIpsVhMmerSJIlE4ny0rKyMHGXYuxOmCuO96XRPnJC6JSln5bQsMp3Nv5zzyheZpU0FNFrIbjIyMqxWq1Kp7L9zmms0Go1GIxknh4j6NRqN1Wod8rLkKyIlJYV88MhnwAHyrWK1WiUSCfX51Gq1YrHY+dsJAMxms9lsHsQkomzyUaFOoz4DI0LutGAvektX84EL21/9YrVzzgdxxmQylZWVOeTsAMBqtarVampcKBQST2y1Wm+HBwNjNBoVCoXBYCDicwmRqVgstj+NvMulywcAb0xij9wJRPRpU9JDAkMbbOYd5dn66t0Y0A+OTCZzGSEIhUIHl0xJcDjeHQBcenR7iAtXKBQO4haLxS7jKC9NYpvcCWlT0rck5ZDszSf17z9fnO7WVJhruIx3AcDlZ2D4DBRnU5DIZCADXA56aRI75Q4AIYH8ldOy18/cRgJ67dnNeyo3o5t3iZca8viylD8eKG6hHdbKnTBVGE9iGwCo/K74lS8yMZp3xkdqG/Ky7oZG3sNyuRPSpqQ/O3s3mcLuKM/Ov5zDtEXMQCKHkYNYLCaKdznLNBqNtN+RE3IHgEh+9HOzd5NoPv9yzhtfZrE4sCEachC31Wp1mdpjFjIf1el0Dg6e5EBpv92Acu89e64n/xj56W9tpf3G/odE8yunZYUEhla3VL7yRWaDrYZpo3wCmeSRKiYZ0el0UqnUbzHD8CFpFrPZLJVKKR+v0WhIn7CXF3f+0nAh9578Y22PL2l7fIltzTryY41PaF+xyst7jxASJ6T+4aHtJLB548ssVmZs1Go1SUXL5XJSRc/IyDCZTEOmBf0PqS4BgMlkIvV/Ho+nUqmsVqtCofDmsgBgNBodmggc5d6Tf8y2Zl3v2XNj5iUFZyqCMxWBM6bzwsL6W9s8vvdIgwQ2MeFxJGPDvvorqdrY561lMllZWZlCoVAqlYMUfRiBss1hxJt8kUKhcJm2d+yZaX1s8ff33d+h3uowfuPrusHbJFwyzJ4Zpth/fivptNl/3vHvRRiHfBeRnmG6cB2799XVO4wETIry+KM2Ylk5LXtZzGoAKG0yHLiwjWlzuAhpw5RKHffnoibWA5XAPMNR7mOffAIAevKPta9YxY4Z6uAkRy0lHcioeEYgMYzRaJTL5VQqSa/XS6VSs9ksFAq9ieBd4OzwO9/UkiDEEifp/vAjb747RngwQ1Hyzb8xqmEK59Y0CuceZi+5w7v31dXb1qzr3KMDAF5YWH9rq23Nuq7dOjo/XiOSxAmp6OOZQqlUOkxVyWBNTQ3ts+rbC2907dYRoY996ongJ5fzwsZd02zvfvcQANytzA7O9OQ7Zchds0cUpU0FBy5sB4DECdKV07KZNgehn5ty7373UMezm3hhYYKD+wJnTKcO29as68k/xgsLCz9xnBcW5u7VR5fcwU7xaVPScW8F9hEAAP2trdc02wHgbmWWvdYBIHi1gpxw/SQLyzHOUFFN/uUc9uXjkQAA6H73cH9ra+CM6WOfWu5w+K5b+cfec+f8bRpDJE5IJesjHLiwHdsnWUYAAPR8dAwAAucNtjRX4PTpgxxlGbKYTNJMpj27mWuLN7GbAAC4UVcPAHdFuSgk9Z79D3nhEOSwHllMZiRf3Nnboa18kcW9k1wjoL+1lZSTXM5EieMfMy+JlVXVQQgJ5P/hoe3kgVd99W6mzUHoIYAXFkaE7tw4QHqAAWDsk44xPRcICeRnzNgMAKVNBhZMW18oWZV1YsCVCX0H1edIcNmEvGzNB6mr3OvF7373UPuKVZbJMeSnfcUqolWC/bpLjh2RgTN+AgCde3S9Z2/PR6+fLL727Kb+1taxTy0PSnvUg7+TBVAL4Oird4/q5viCrw9/19nEtBWuyck739jsXrjY8eymjmc32WcLr58sHk5JNAAAQpTZpIbavuJ/2lesuqbZ1vb4kvYVq3rPngtKezT01Zft33BNs436SJGftseXsDhNmTYlnbQKHzg/KqutX3574m/ntuTVvMWsGVQ7gP1DG4Uldc+99tmbB13vLD0Q3e8eItXPMfOShGfKRLXV4ScKx8xLAoBrmm1EitSiYg7PiAQCQOCM6YKD+2xr1vXV1V8/WUzeEDApKvjJ5c7F1N6TxYEzpo/7181dCagPSfiJQrbG96vjNj9fnN5gM+dfzhlFtaesE0uvjdRJduoqfXtHj2fv7f7HYbgp2v1kJGBSlODg/pb5yX119d3/ODRm4BzjzZ6ZwBnTw08UCg7u5+/ayd+1U3Bwf/iJQmet97e29p49d5ddloYXFkZKUddPfu6Z9SMf8tQfAORfzhnVIQ0L6KurJyE3ad21J/jJ5QAweKBxx/rug3wsCC5TlmSO60GLwSgifnxS3A+SKr8rPnB+27Oz9zBtzrDYPv8o9ZqENAwa40DB/tu9XySkGeYbqenlmHkPOxwiXph45IHy5u6tRNB7shjuLEhdP1ncuUcXOGM666ezqx7IInnJwvqjQ5/NauRy+TB3iaIdyrc6R84k4wKucoy3z3HrZjfq6wGg7fEl9oNjn1ruMJ1lJSGB/LQp6Ueq9+Rfzpk7IZXL+x4rlcqEhASxWMzUY6+8sHGuBsNIxmWQx5Lc8+43zp4bMy9JVFtN/QTOmM7iqN2B5KilJEvD8cKTRCJRKpWM+Pi+tlYACBg0ch5kGQE35O48TwWAoF882ldXP8jXB8sgmZnSJgPH56xqtVoikahUKrlczrQtbuCG3En/jMM8lYQ3bE1BOjNVGE+6x/SX2ODgTSYTz1NIqVKv10dHR/vN4IBxYXArZeKAXTuMi1CH4EbsfuPsObg1/6Xoq6vjjtYJaVNWljYZqlsqL1nPkO1g/YP69Jq69iEelJkkiFHN2jX8a5KtYDyzJyEhwWQyKRQKrVbr2RV8xCBJQne8+7lz4Ko1sr+1jQtrFlDcExxBGuI5u7QqAJBlyXJzc/2sdeK5+1tbXbV4/efWOQPK3Q3vzt+1E5wcB1XZ4hSPTUkvbSrws4N3y237FKPRqNPpcnNz/Z+ZodLt109+7vA0Eok+eGFhQ1dVEbcICeSTvYu56eBVKpVWq2UkCxkwKYrEF6SVwJ6ufxwCu+y767f7zjJ2Q7b5Jg6eaVv8jfM6GT6C6uO1X6qbtA/0nj1HrfzV39ravmIVCW8Gb1ZHuXvIPcERJEVTemXUt8KPLqiO9Osni63xCZbJMdb4BNIqE5ypGLy6j3L3nLQpKwGgtMmAz7P6Gf6unaGvvmwfo4+Zl8TftfNu5VCrA9G7KJkDo2XRPI953bQh87jUmy2/aaHAWFB6qoRZGwaCrGnqzfJ3ZPNUj98LI23X7NHL3AmpAFDC6KN9W/60ZcVT6Z3Xuhi0wXfo9XqypzYtV0O5e0XihNSQwFBLVzMju4DU1tYuWLCw0FB46lTpwoUL/W+AryHbzA+0y7EHoNy9hWQkz3zn7z65oqKiOXMSZ82WFBYWTp482c93dxdq2xy39ocyGo3UbjZuQaV0HG7nXgMw4szcCamf1L9/5mpxZ4zNb13BW7duff311/+66y+yZSNr5xl6oX0zqdsrAPuCUbckqmc8X5xu6WpeOS2LeHqf0tLS8tvf/qa1tXXbtu0PPvigr2/HMjCYoYH48UkAcKnF5/WmioqKBQsWTp4yWa8/glr3AJQ7DZD8jK9nq3v37p05c+batWu2b3stPDzcp/diKxi700AkP5ps1HrmajHx9PTS0tKy5ZWXDQXHy8vL0al7A3p3evBdPFNRUSGTLau9XPvpp0WodS9BudPD1PB4AKimu11Mf0T/85//XCpNPXLkPQxgvAeDGXqYKowDgAabubOXtnTklj9t+cuOvx4+fIiVJSRGQLnTQ0ggP5IvbrCZL1krvQ/fa2trf/3rX9+40XfqVOnILyGNIjCYoY0YYTzQEb7n5eXNmZOYLE3+9NMi1Dq9oNxpg4TvDe1eLcixY+eO1atX/3XXX57/v+dpsgu5DQYztBEpiAaA6pZKz95OyqUWi/Xjjz/GDIyPQO9OG/cER4QEhgKA84pLnb22wR8Bqaio+PGPYydPmXz06FHUuu9AudNJJD8aAL7vvK3szl5b/uWcV77IHORdpFz6111/wXKpr8FgxkMabDUHzm+LFETH/+DhqcI4knycKoyvbqlssNXEj0/6vqs5//KB0iYDACyLWX1PcITzRVpaWp555g8mUzmWS/0Dyt1DIvnRaVNWas9uJoKOCY+bKozvvtEFAFWWLy9Zz1BBfCRfTJYtcKCioiI7O2uKeMqnnxahU/cP2ADsFYX1R49UD7G7wfqZ25yXXtIf0f9+7e+feeaZjRs3+sw6xBH07l6RHLX0krWy8rsBeyGJ13cYzMrekHPgHftyadO3HYLQMfzQIN+ZigBOVb1n1QNZIldxOcFh67La2trk5OTTX5guXqyybw0QhI5Jz/qoutaNB9sQD0C5e0tIIH/ltCyXhxxce15eXmJi4vwF852DdX5o0EM/iViZ9dHhD6t8ay63QbnTwFRhPFkT2AF7107KpTnv5Gx+cbPLiyyYHQkAO/aZnn7B0PRth28s5Tood3p4bEo6qTFRiIIjiGtvaWlZtuyX/8z758cffyx9RDrQFebPjuLfPQYAys9/uzIrH928L0C500NIIF8Wc0ctKTlqCQAUFRUNv1w6f/bNjSFs167v2Gdakpn35X9wOT46QbnTRuKE1JjwOOrXuRNS9+7du2jRouGXS5c/Fmv/65WrHWteND79ggFFTxeYd6eTS9YzO8qzASCen3Rqz9cmU/n+/fvcKpcuycy7ctVF4P6LheLlj8XGTBbSZisnQe9OJ1OF8cTBx0clxT/0oAdPl6Ytcr063EdF5pVZH6Gn9xLflpku3hsNAGO59B+6H5ZVQ2X/97E/XRRvbuyGRvf+9vsmDrZjaPn5b9e8aIyZLHwiLXbB7EgsS7mLb4OZucve8d3FRyyiGd9Yzv7I13fh3z3mt/K4J+4M95HB8a13TxprAYDOaI79S2788L4HPH1rX39l1dUhT/vFQnHaIvFDPxmwmou4xLfeHXGX/E/MW3aVDHSUf/eYJx6LTVsYPeGHoQOdgwwCtoiNLA7nu64u3Ts+dHlabNoiMcbr3oByH0E0fdvh3CVGPPpv5XEu34K4Bcp9BJFf5PiQ62/kM5anxaJHpwuU+wgi/xMz9Xr+rMj1v0rAGJ1eUO4jhepaK6mn8u8es2ntXKp/BqERlPtIgbj2+bMiN62di9GLj0C5jxTyP6lZ/z8SLBv5FPbn3QtL6siLH0XwY8UiZo0ZCJKQwQ4wX8Naubd39Lx5sPx4cV17Rw81KAgNUq2ekzx3EoOGIQzC2mDmudc+O115ZWIE/5GkSYLQoMZm2zfNtiqzhWm7ECZhp9wLS+pOV14RhAb9feujArtpX5XZMmLjGcQPsLnfvb2jp6rmDneOWuc47JR78txJRNnPvfZZTt55ps1BRgpsnqqu++NxEqwvlt7/9IqZAkxmcx52yj0n73xh8ddVZosgNIhkZmLFop0vPoKK5zhsk3t7Rw/JycyKu3exNCZ57qTCkjr1nlPtHT2oeIRtcv/VxmNVZsti6f3KjDnU4OnKK+teOg4A6YsfeHrFTOasQxiGVVPVNw+Wk1SjvdYBYFbcvaS0dLryCkOmISMCVsmd9Av8tzTG+dDECD4AVJkt9kVWhGuwR+6FJXWNzTYAeCRpwB6BWLEIY3cuwx65E60PJGiSkYyNxjITp2GP3Ntt3QMdamy2kah9VtwEP1qEjDjYI3cBfyzc8vEOHMz7D9hNWBHOwh65k66B9o4ejfaU/fibB8vzDF8JQoMwBYmwKu+u0Z7KM3wFALFiUWy0qM3Wc9FsaWy2Obe5Nzbblq35ANPwXINVDcAk3Z5n+KrKbKFa25PnTnp6xUySiKS4eHPmeo//jUQYhFVyBwBlxpwVi39y8ZbWfywWOQidUFXzPQD8yNUhhMWwTe4AMDGC71Li9pAIB9vfuQZ7pqpuQZ7rY9oKxN9wUe6klWBW3L1MG4L4Gy7K/ZtmGwD8KELAtCGIv+Gi3Mk8FRsKOAgn5W624DyVm3BS7jUWnKdyE1ZVVYdDldnyq43HnMd3vvAITl5ZD+fkjnAZLgYzCGdBuSMcAuWOcAiUO8IhUO4Ih0C5IxwC5Y5wCJQ7wiFQ7giHQLkjHALljnCI/wealUCnKPwAAAACSURBVBqAIW7EQQAAAABJRU5ErkJggg==)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurningNMF1D(TurningNMF):\n",
    "    def __init__(self, r=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Define the action space using spaces.Box (1 line of code)\n",
    "        # Refer to https://www.gymlibrary.dev/api/spaces/#gym.spaces.Box for details\n",
    "\n",
    "        self.action_space = ...\n",
    "        ############################################################################\n",
    "\n",
    "    def step(self, action):\n",
    "        ############################################################################\n",
    "        # TODO: Convert the 1D action to 2D action  (~2 lines of code)\n",
    "\n",
    "        action = ...\n",
    "        ############################################################################\n",
    "        return super().step(action)\n",
    "\n",
    "\n",
    "nmf1d = TurningNMF1D(\n",
    "    sim_params=sim_params,\n",
    "    contact_sensor_placements=contact_sensor_placements,\n",
    "    spawn_pos=(0, 0, 0.2),\n",
    ")\n",
    "\n",
    "check_env(nmf1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a triangle wave as the action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import sawtooth\n",
    "\n",
    "run_time = 4\n",
    "n_steps = int(run_time / nmf.sim_params.timestep)\n",
    "actions = sawtooth(np.linspace(0, 4 * np.pi, n_steps), 0.5)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 2), tight_layout=True)\n",
    "ax.plot(np.arange(n_steps) * nmf.sim_params.timestep, actions, c=\"k\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_hist = []\n",
    "obs, info = nmf1d.reset(seed=0)\n",
    "\n",
    "for i in trange(n_steps):\n",
    "    obs = nmf1d.step(actions[i])[0]\n",
    "    obs_hist.append(obs)\n",
    "    nmf1d.render()\n",
    "\n",
    "nmf1d.save_video(\"./outputs/turning1d.mp4\")\n",
    "Video(\"./outputs/turning1d.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the trajectory of the fly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# TODO: get the fly's trajectory from obs_hist\n",
    "trajectory = ...\n",
    "#################################################################\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3), tight_layout=True)\n",
    "ax.plot(trajectory[:, 0], trajectory[:, 1], color=\"k\")\n",
    "ax.set_xlabel(\"x (mm)\")\n",
    "ax.set_ylabel(\"y (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What limitation does the `TurningNMF1D` class have compared to the `TurningNMF` class?\n",
    "\n",
    "TODO: Your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flygym0.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
